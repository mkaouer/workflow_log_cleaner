{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP937uLNmESQoITUh7CsEh4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sravyasambaturu/workflow_log_cleaner/blob/main/self_refinement_for_logs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60hLvY2zjZAD",
        "outputId": "46511d87-28df-4ddf-ecbc-394dbbe55714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the path to your Excel file\n",
        "excel_file_path = '/content/Copy of survey_data.xlsx'\n",
        "\n",
        "# Read all the explanation sheets into a dictionary of dataframes\n",
        "dfs = {}\n",
        "for i in range(10):  # Assuming sheets are named 'explanation 0' to 'explanation 9'\n",
        "    sheet_name = f'Explanation {i}'\n",
        "    dfs[sheet_name] = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
        "\n",
        "# Combine all the dataframes into one\n",
        "combined_df = pd.concat(dfs.values(), ignore_index=True)\n",
        "\n",
        "# Optional: save the combined dataframe into a new Excel file\n",
        "combined_df.to_excel('combined_explanations.xlsx', index=False)\n",
        "\n",
        "# Display the first few rows of the combined table\n",
        "print(combined_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YAr2Nz-jldB",
        "outputId": "a3ad179d-9661-42b5-cc66-ce8f8671a471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Line number                                  Error information  \\\n",
            "0          1.0  Error response from daemon: manifest for medic...   \n",
            "1          2.0                                                NaN   \n",
            "2          3.0        1) \"before all\" hook: beforeAll in \"{root}\"   \n",
            "3          4.0                                                NaN   \n",
            "4          5.0                                          1 failing   \n",
            "\n",
            "                                      Log file  IsText  \\\n",
            "0  ##[group]Run npm run ci-integration-all-k3d     0.0   \n",
            "1               npm run ci-integration-all-k3d     0.0   \n",
            "2                  shell: /usr/bin/bash -e {0}     0.0   \n",
            "3                                         env:     0.0   \n",
            "4      COUCH_URL: ***localhost:5984/medic-test     0.0   \n",
            "\n",
            "                                         Explanation  \n",
            "0  The error message \"Error response from daemon:...  \n",
            "1                                                NaN  \n",
            "2  This error typically occurs when the Docker im...  \n",
            "3                                                NaN  \n",
            "4                                Possible solutions:  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Data for each explanation for llama_3_70_b (Correctness, Relevance, Depth, Clarity, Formatting)\n",
        "data = {\n",
        "    'Correctness': [4, 5, 5, 4, 5, 5, 5, 5, 5],\n",
        "    'Relevance': [5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
        "    'Depth of Analysis': [4, 5, 4, 3, 4, 4, 5, 4, 4],\n",
        "    'Clarity': [5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
        "    'Formatting': [4, 5, 5, 5, 5, 5, 5, 5, 5]\n",
        "}\n",
        "\n",
        "# Calculate the average for each metric\n",
        "averages = {metric: np.mean(scores) for metric, scores in data.items()}\n",
        "averages\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmROfbBbChav",
        "outputId": "0013a84c-4ab6-40e5-eeeb-b5b3c7c222f0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Correctness': np.float64(4.777777777777778),\n",
              " 'Relevance': np.float64(5.0),\n",
              " 'Depth of Analysis': np.float64(4.111111111111111),\n",
              " 'Clarity': np.float64(5.0),\n",
              " 'Formatting': np.float64(4.888888888888889)}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Data for each explanation for GPT-4o(values for correctness, relevance, depth, clarity, formatting)\n",
        "data = {\n",
        "    'Correctness': [4, 5, 4, 3, 5, 5, 4, 4, 5, 5],\n",
        "    'Relevance': [4, 5, 4, 4, 5, 5, 4, 4, 5, 5],\n",
        "    'Depth of Analysis': [3, 4, 3, 2, 4, 5, 3, 3, 5, 4],\n",
        "    'Clarity': [4, 4, 4, 4, 4, 5, 4, 4, 5, 4],\n",
        "    'Formatting': [4, 4, 4, 4, 4, 5, 4, 4, 5, 4]\n",
        "}\n",
        "\n",
        "# Calculate the averages for each metric\n",
        "averages = {metric: np.mean(scores) for metric, scores in data.items()}\n",
        "\n",
        "averages\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYT0tgUADK_3",
        "outputId": "e7e21709-df96-478d-8c6c-d48364e72933"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Correctness': np.float64(4.4),\n",
              " 'Relevance': np.float64(4.5),\n",
              " 'Depth of Analysis': np.float64(3.6),\n",
              " 'Clarity': np.float64(4.2),\n",
              " 'Formatting': np.float64(4.2)}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Data for llama70b\n",
        "llama70b = {\n",
        "    \"Correctness\": 4.78,\n",
        "    \"Relevance\": 5.00,\n",
        "    \"Depth of Analysis\": 4.11,\n",
        "    \"Clarity\": 5.00,\n",
        "    \"Formatting\": 4.89\n",
        "}\n",
        "\n",
        "# Data for Self-Refinement Results for GPT-4\n",
        "gpt4 = {\n",
        "    \"Correctness\": 4.5,\n",
        "    \"Relevance\": 4.7,\n",
        "    \"Depth of Analysis\": 3.6,\n",
        "    \"Clarity\": 4.4,\n",
        "    \"Formatting\": 4.4\n",
        "}\n",
        "\n",
        "# Convert the dictionary values into lists (arrays)\n",
        "llama70b_scores = list(llama70b.values())\n",
        "gpt4_scores = list(gpt4.values())\n",
        "\n",
        "# # Perform a t-test to compare the means of both datasets\n",
        "# t_stat, p_value = stats.ttest_ind(gpt4_scores, llama70b_scores)\n",
        "\n",
        "# print(f\"T-statistic: {t_stat}\")\n",
        "# print(f\"P-value: {p_value}\")\n",
        "\n",
        "\n",
        "mean_diff = np.array(list(llama70b.values())) - np.array(list(gpt4.values()))\n",
        "print(\"Mean Differences per Metric:\", mean_diff)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svLRLDXIEAjb",
        "outputId": "8f567f17-0176-45bd-adf4-c91eeee2d471"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Differences per Metric: [0.28 0.3  0.51 0.6  0.49]\n"
          ]
        }
      ]
    }
  ]
}